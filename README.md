<<<<<<< HEAD
# ai-meeting-assistant
=======
# ðŸ§  AI Meeting Assistant ðŸŽ§

A lightweight voice-based assistant that listens to your voice (like in Zoom or Google Meet), transcribes it, and responds intelligently â€” all **offline using Ollama and local LLMs** like TinyLLaMA or Phi-3.

---

## ðŸš€ Features

* ðŸŽ¤ Voice recording with 1-click
* ðŸ§  Speech-to-text transcription using Whisper
* ðŸ’¬ Natural responses using local LLMs via Ollama
* ðŸ’» Runs fully **offline** (no API keys or billing required)
* ðŸ’‡ï¸ Lightweight models (works with as low as 2GB RAM)

---

## ðŸ“ Folder Structure

```
ai-meeting-assistant/
â”‚
â”œâ”€â”€ app.py                 # Streamlit app
â”œâ”€â”€ audio_utils.py         # Audio recording logic
â”œâ”€â”€ transcribe_utils.py    # Whisper-based transcription
â”œâ”€â”€ ai_utils.py            # Ollama-based response generation
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

---

## ðŸ’ª Installation & Setup

### ðŸ”§ Prerequisites

* Python 3.10 or later
* Pip + virtualenv
* Streamlit
* Whisper
* Ollama

---

### ðŸ“† Step 1: Clone the repo

```bash
git clone https://github.com/your-username/ai-meeting-assistant.git
cd ai-meeting-assistant
```

---

### ðŸšª Step 2: Create virtual environment and install dependencies

```bash
python -m venv venv
venv\Scripts\activate     # On Windows
# source venv/bin/activate  # On Mac/Linux

pip install -r requirements.txt
```

> ðŸ“ Sample `requirements.txt`:

```txt
streamlit
whisper
sounddevice
numpy
ollama
python-dotenv
```

---

### ðŸ§  Step 3: Install and Run Ollama

#### âœ… Download Ollama:

[https://ollama.com/download](https://ollama.com/download)

#### âœ… Run a lightweight model (recommended for low RAM):

```bash
ollama run tinyllama
```

> First run will download the model (\~400MB). Keep the terminal open.

---

### ðŸƒï¸ Step 4: Run the App

```bash
streamlit run app.py
```

Open in browser â†’ [http://localhost:8501](http://localhost:8501)
Click **â€œStart Listeningâ€** and speak for 5 seconds. You'll get a transcription + intelligent response.

---

## ðŸ“¸ Screenshots

| Record Audio | Get Answers |
| ------------ | ----------- |
|              |             |

---

## ðŸ§ Model Options

Supported local models (via Ollama):

* `tinyllama` âœ… (ideal for low memory)
* `phi3` (lightweight)
* `gemma:2b` (medium size)
* `llama3` (only if > 6GB RAM)

Update `ai_utils.py` to switch models:

```python
client.chat(model='tinyllama', ...)
```

---

## ðŸ“Œ To-Do / Improvements

*

---

## ðŸ§‘â€ðŸ’¼ Author

**Riya Sonal Nazareth**
ðŸ”— [LinkedIn](https://www.linkedin.com/in/riya-sonal-nazareth-20b26a227/)
ðŸ’» [GitHub](https://github.com/Riya-sonal)

---

## ðŸ“œ License

This project is open source under the [MIT License](LICENSE).
>>>>>>> d7d6642 (Initial commit with working AI Meeting Assistant and README)
